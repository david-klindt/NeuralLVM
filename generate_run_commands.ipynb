{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 num_sample 1\n",
      "1 num_neuron_train 1\n",
      "3 seed 3\n",
      "3 kernel_size 1\n",
      "3 num_hidden 1\n",
      "6 shared 2\n",
      "6 learn_coeff 1\n",
      "12 learn_mean 2\n",
      "24 learn_var 2\n",
      "24 isotropic 1\n",
      "72 num_basis 3\n",
      "72 batch_size 1\n",
      "72 batch_length 1\n",
      "144 learning_rate 2\n",
      "144 num_worse 1\n",
      "432 weight_kl 3\n",
      "432 weight_time 1\n",
      "432 weight_entropy 1\n",
      "864 nonlinearity 2\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        # data (this is more to check)\n",
    "        'num_sample': [10000],      # [1000, 10000, 100000]  # only do the one in the middle\n",
    "        'num_neuron_train': [50],   #  : [10, 50, 100]   # only do the one in the middle\n",
    "        'seed': [15645, 56512, 98148],\n",
    "\n",
    "        # model\n",
    "        'kernel_size': [9],\n",
    "        'num_hidden': [256],\n",
    "        'shared': [True, False],\n",
    "        'learn_coeff': [True],\n",
    "        'learn_mean': [True, False],\n",
    "        'learn_var': [True, False],\n",
    "        'isotropic': [True],\n",
    "        'num_basis': [1, 2, 4],\n",
    "\n",
    "        # # training\n",
    "        'batch_size': [32],\n",
    "        'batch_length': [128],\n",
    "        'learning_rate': [1e-3, 1e-2],\n",
    "        'num_worse': [50],\n",
    "        'weight_kl': [1e-9, 1e-6, 1e-3],\n",
    "        'weight_time': [0],\n",
    "        'weight_entropy': [0],\n",
    "        'nonlinearity': ['exp', 'softplus']\n",
    "    }\n",
    "\n",
    "n = 1\n",
    "for k, v in params.items():\n",
    "    n *= len(v)\n",
    "    print(n, k, len(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--batch_length 128 --batch_size 32 --isotropic True --kernel_size 9 --learn_coeff True --learn_mean True --learn_var True --learning_rate 0.001 --nonlinearity softplus --num_basis 1 --num_hidden 256 --num_neuron_train 50 --num_sample 10000 --num_worse 50 --seed 98148 --shared False --weight_entropy 0 --weight_kl 1e-09 --weight_time 0 \n",
      "--batch_length 128 --batch_size 32 --isotropic True --kernel_size 9 --learn_coeff True --learn_mean False --learn_var True --learning_rate 0.001 --nonlinearity exp --num_basis 4 --num_hidden 256 --num_neuron_train 50 --num_sample 10000 --num_worse 50 --seed 98148 --shared True --weight_entropy 0 --weight_kl 0.001 --weight_time 0 \n",
      "--batch_length 128 --batch_size 32 --isotropic True --kernel_size 9 --learn_coeff True --learn_mean False --learn_var True --learning_rate 0.001 --nonlinearity exp --num_basis 4 --num_hidden 256 --num_neuron_train 50 --num_sample 10000 --num_worse 50 --seed 98148 --shared False --weight_entropy 0 --weight_kl 1e-06 --weight_time 0 \n",
      "--batch_length 128 --batch_size 32 --isotropic True --kernel_size 9 --learn_coeff True --learn_mean False --learn_var True --learning_rate 0.01 --nonlinearity softplus --num_basis 1 --num_hidden 256 --num_neuron_train 50 --num_sample 10000 --num_worse 50 --seed 56512 --shared True --weight_entropy 0 --weight_kl 1e-06 --weight_time 0 \n"
     ]
    }
   ],
   "source": [
    "base = ''  # python NeuralLVM/tests.py test_training --... \n",
    "pg = np.array(ParameterGrid(params))\n",
    "np.random.shuffle(pg)\n",
    "for i, combination in enumerate(pg):\n",
    "    cmd = base\n",
    "    for key, val in combination.items():\n",
    "        cmd += f'--{key} {val} '\n",
    "    print(cmd)\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu month 29.16\n"
     ]
    }
   ],
   "source": [
    "runtime_minutes = 30\n",
    "print('gpu month', (len(pg) * runtime_minutes ) / 60./24. / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python NeuralLVM/tests.py test_training --batch_length 128 --batch_size 32 --isotropic True --kernel_size 9 --learn_coeff True --learn_mean False --learn_var True --learning_rate 0.001 --num_basis 2 --num_hidden 256 --num_neuron_train 50 --num_sample 10000 --num_worse 50 --seed 98148 --shared False --weight_entropy 0 --weight_kl 1e-06 --weight_time 0 \n",
    "\n",
    "\n",
    "number of trainable parameters in model: 99532\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/tests.py\", line 208, in <module>\n",
    "    fire.Fire()\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\n",
    "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/fire/core.py\", line 466, in _Fire\n",
    "    component, remaining_args = _CallAndUpdateTrace(\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
    "    component = fn(*varargs, **kwargs)\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/tests.py\", line 190, in test_training\n",
    "    output = trainer.train()\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/training.py\", line 100, in train\n",
    "    output = self.model(y_train, z=z)\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/model.py\", line 376, in forward\n",
    "    responses_train, responses_test = self.decoder(output['z'])\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/model.py\", line 299, in forward\n",
    "    self.feature_bases_train[i](z[i], self.receptive_fields_train[i], test=False)\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/model.py\", line 199, in forward\n",
    "    dist = dist / torch.exp(log_var[None, None])\n",
    "RuntimeError: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "python NeuralLVM/tests.py test_training --batch_length 128 --batch_size 32 --isotropic True --kernel_size 9 --learn_coeff True --learn_mean True --learn_var True --learning_rate 0.001 --num_basis 4 --num_hidden 256 --num_neuron_train 50 --num_sample 10000 --num_worse 50 --seed 98148 --shared True --weight_entropy 0 --weight_kl 1e-09 --weight_time 0 \n",
    "\n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/tests.py\", line 208, in <module>\n",
    "    fire.Fire()\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\n",
    "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/fire/core.py\", line 466, in _Fire\n",
    "    component, remaining_args = _CallAndUpdateTrace(\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
    "    component = fn(*varargs, **kwargs)\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/tests.py\", line 190, in test_training\n",
    "    output = trainer.train()\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/training.py\", line 100, in train\n",
    "    output = self.model(y_train, z=z)\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/model.py\", line 376, in forward\n",
    "    responses_train, responses_test = self.decoder(output['z'])\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/model.py\", line 299, in forward\n",
    "    self.feature_bases_train[i](z[i], self.receptive_fields_train[i], test=False)\n",
    "  File \"/home/scl1pal/.conda/envs/lvm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"/home/scl1pal/projects/NeuralLVM/exp/run_2022-05-13-22-44-28/NeuralLVM/model.py\", line 199, in forward\n",
    "    dist = dist / torch.exp(log_var[None, None])\n",
    "RuntimeError: The size of tensor a (2) must match the size of tensor b (16) at non-singleton dimension 4\n",
    "\n",
    "\n",
    "\n",
    "weitere Info:\n",
    "--batch_length 128 --batch_size 32 --isotropic True --kernel_size 9 --learn_coeff True --learn_mean False --learn_var True --learning_rate 0.01 --nonlinearity softplus --num_basis 1 --num_hidden 256 --num_neuron_train 50 --num_sample 10000 --num_worse 50 --seed 56512 --shared True --weight_entropy 0 --weight_kl 1e-06 --weight_\n",
    "und \n",
    "\n",
    "--batch_length 128 --batch_size 32 --isotropic True --kernel_size 9 --learn_coeff True --learn_mean True --learn_var True --learning_rate 0.001 --nonlinearity softplus --num_basis 1 --num_hidden 256 --num_neuron_train 50 --num_sample 10000 --num_worse 50 --seed 98148 --shared False --weight_entropy 0 --weight_kl 1e-09 --weight_time 0 \n",
    "\n",
    "laufen. KÃ¶nnte also gut an num_basis liegen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 10\n",
      "i 20\n",
      "i 30\n",
      "i 40\n",
      "i 50\n",
      "i 60\n",
      "i 70\n",
      "i 80\n",
      "i 90\n",
      "i 100\n",
      "i 110\n",
      "i 120\n",
      "i 130\n",
      "i 140\n",
      "i 150\n",
      "i 160\n",
      "i 170\n",
      "i 180\n",
      "i 190\n",
      "i 200\n",
      "i 210\n",
      "i 220\n",
      "i 230\n",
      "i 240\n",
      "i 250\n",
      "i 260\n",
      "i 270\n",
      "i 280\n",
      "i 290\n",
      "i 300\n",
      "i 310\n",
      "i 320\n",
      "i 330\n",
      "i 340\n",
      "i 350\n",
      "i 360\n",
      "i 370\n",
      "i 380\n",
      "i 390\n",
      "i 400\n",
      "i 410\n",
      "i 420\n",
      "i 430\n",
      "i 440\n",
      "i 450\n",
      "i 460\n",
      "i 470\n",
      "i 480\n",
      "i 490\n",
      "i 500\n",
      "i 510\n",
      "i 520\n",
      "i 530\n",
      "i 540\n",
      "i 550\n",
      "i 560\n",
      "i 570\n",
      "i 580\n",
      "i 590\n",
      "i 600\n",
      "i 610\n",
      "i 620\n",
      "i 630\n",
      "i 640\n",
      "i 650\n",
      "i 660\n",
      "i 670\n",
      "i 680\n",
      "i 690\n",
      "i 700\n",
      "i 710\n",
      "i 720\n",
      "i 730\n",
      "i 740\n",
      "i 750\n",
      "i 760\n",
      "i 770\n",
      "i 780\n",
      "i 790\n",
      "i 800\n",
      "i 810\n",
      "i 820\n",
      "i 830\n",
      "i 840\n",
      "i 850\n",
      "i 860\n",
      "i 870\n",
      "i 880\n",
      "i 890\n",
      "i 900\n",
      "i 910\n",
      "i 920\n",
      "i 930\n",
      "i 940\n",
      "i 950\n",
      "i 960\n",
      "i 970\n",
      "i 980\n",
      "i 990\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1000):\n",
    "     if i > 0 and not (i % 10):\n",
    "        print('i', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d6eb8f4b98ce0692a6f1f6e6443eea96ab18ea7ee16a9dde68ec43b4df3f39a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('lvm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
